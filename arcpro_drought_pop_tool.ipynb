{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Overview\n",
    "\n",
    "This tool should allow you to read in a csv file with latitude, longitude, and year columns of point data (specifically designed for forest plots) and output a csv file and a feature class that both contain values for the palmer drought severity index in the county of the point in the previous summer, the total popultation in the appropriate year and the population/square mile of the county that the point falls into. All data besides the CSV are accessed via API's. However, this tool will only work when the CSV data has a year range between 2000 and 2018, otherwise I will need to make additional requests on the census API. This tool has 8 inputs:\n",
    "\n",
    "0. space --> where we will create a geodatabase to store output and store our ouput CSV\n",
    "1. incsv --> input csv with lat lon and year component\n",
    "2. longitude --> (will be set to lon in tool) the column in the csv where longitude is stored\n",
    "3. latitude --> (will be set to lat in tool) the column in the csv where latitude is stored\n",
    "4. plot_year --> (will be set to invyr in tool) the column in the csv where the year is stored\n",
    "5. usename --> username for arcgis (I give permission to use my username: hjs5td)\n",
    "6. passwrd --> password for arcgis (password: Hondoo12)\n",
    "7. key --> key for Census API (I give permission to use my key: a8240e46395d6100bb5585e555c6c5be99584107)\n",
    "\n",
    "as space and the incsv to match your computer, this should work.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1 : Reading a CSV and Create Point FeatureClass of Plot Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.\n",
    "**Import Python Modules**\n",
    "    - arc modules\n",
    "        - arcgis gives access to arcgis api\n",
    "        - arcpy gives access to eveything available in arcpro software (functions, layout etc.)\n",
    "    - other moduels\n",
    "        - pandas is used for data analysis and manipulation\n",
    "        - numpy is used for math\n",
    "        - sodapy is a module recommended by CDC to use their API\n",
    "        - zipfile used to unzip zipfiles\n",
    "        - os gives access to basic functionalities of the computer (creating folders, path names, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcgis\n",
    "import arcpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sodapy\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "import json\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.\n",
    "**set up inputs to convert CSV to featureclass**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up directory and geodatabase\n",
    "\n",
    "space = os.getcwd()\n",
    "\n",
    "incsv = os.path.join('in_data','plot_sample.csv')\n",
    "\n",
    "# these are the names of longitude and latitude in your CSV \n",
    "\n",
    "longitude = 'lon'\n",
    "\n",
    "latitude = 'lat'\n",
    "\n",
    "plot_year = \"invyr\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.\n",
    "**create a geodatabase where we will store our data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "outgdb = \"AdvGIS_proj.gdb\"\n",
    "workspace = os.path.join(space, outgdb)\n",
    "\n",
    "if arcpy.Exists(workspace):\n",
    "    arcpy.Delete_management(workspace)\n",
    "\n",
    "arcpy.CreateFileGDB_management(space,outgdb)\n",
    "\n",
    "arcpy.env.workspace = workspace\n",
    "arcpy.env.overwriteOutput = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4.\n",
    "**create a featureclass from CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'C:\\\\Users\\\\hjs5td\\\\Desktop\\\\SudekumFinalProject\\\\AdvGIS_proj.gdb\\\\plots'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define name of featureclass to go into geodatabase\n",
    "plots = \"plots\"\n",
    "plottab = \"plot_table\"\n",
    "\n",
    "#GCS_WGS_1984 geographic coordinate system\n",
    "sr = arcpy.SpatialReference(4326)\n",
    "\n",
    "#USA_Contiguous_Albers_Equal_Area_Conic_USGS_version projected coordinate system\n",
    "pr = arcpy.SpatialReference(102039) \n",
    "\n",
    "arcpy.XYTableToPoint_management(incsv,plots, x_field = longitude, y_field = latitude, coordinate_system = sr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5.\n",
    "**create new feature class projected into equal area projection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'C:\\\\Users\\\\hjs5td\\\\Desktop\\\\SudekumFinalProject\\\\AdvGIS_proj.gdb\\\\plots_proj'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plots_proj = 'plots_proj'\n",
    "\n",
    "transformation = 'WGS_1984_(ITRF00)_To_NAD_1983'\n",
    "\n",
    "#going from sr to pr coordinate system\n",
    "\n",
    "arcpy.Project_management(plots, plots_proj, pr, transformation, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2 : Accessing APIS and Getting Explanatory Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download a Layer From ArcGIS hub\n",
    "http://hub.arcgis.com/pages/open-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.\n",
    "**Set up text inputs for accessing various API's**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs:\n",
    "\n",
    "# username and password of arcgis account\n",
    "\n",
    "usename = ''\n",
    "passwrd = ''\n",
    "\n",
    "# census key can be requested at : https://api.census.gov/data/key_signup.html \n",
    "\n",
    "key = ''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. \n",
    "**set up numeric variables to be used for PDSI API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used in the sql clause for CDC API\n",
    "# does not require a key or username+pass\n",
    "\n",
    "minmonth = 6\n",
    "maxmonth = 8\n",
    "minyear = 1998"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.\n",
    "**get URL of a county feature layer from arcgis hub website.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FeatureLayer url:\"https://services.arcgis.com/P3ePLMYs2RVChkJx/arcgis/rest/services/USA_Counties_Generalized/FeatureServer/0/\">"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL = \"https://services.arcgis.com/P3ePLMYs2RVChkJx/arcgis/rest/services/USA_Counties_Generalized/FeatureServer/0/\"\n",
    "county_layer = arcgis.features.FeatureLayer(URL)\n",
    "county_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**you can use the code below to see what is allowed with this dataset; it says \"extract\" you can directly download the layer as shapefile. see https://developers.arcgis.com/python/guide/checking-out-data-from-feature-layers-using-replicas/**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Query'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "county_layer.properties.capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. (not necessary for the tool)\n",
    "**create a GIS() object; plot a map using the created GIS() object.** Need to create an account in order to download layers directly -- (my username and password are provided in the tool for simplicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f663ad029fd440081255d52cfb75e2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MapView(layout=Layout(height='400px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"map-static-img-preview-86879cfa-265e-4595-8d74-d27965eeccd9\"><img src=\"\"></img></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gis1 = arcgis.gis.GIS(username=usename, password=passwrd)\n",
    "map1 = gis1.map(\"Missouri\")\n",
    "map1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add to a map from a url\n",
    "\n",
    "map1.add_layer({\"type\":\"FeatureLayer\",\n",
    "                \"url\":URL,\n",
    "               })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5.\n",
    "**query all features of the layer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows in the dataset: \n",
      "3142\n"
     ]
    }
   ],
   "source": [
    "all_features = county_layer.query()\n",
    "\n",
    "print('Total number of rows in the dataset: ')\n",
    "print(len(all_features.features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. \n",
    "**create spatial dataframe from the county_layer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store as dataframe pandas dataframe\n",
    "# this works if we can extract the features\n",
    "\n",
    "sdf = pd.DataFrame.spatial.from_layer(county_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7. \n",
    "**delete the columns that we do not need**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FID', 'OBJECTID', 'STATE_NAME', 'STATE_FIPS', 'FIPS', 'SQMI', 'Shape_Leng', 'Shape_Area', 'Shape__Area', 'Shape__Length', 'SHAPE']\n"
     ]
    }
   ],
   "source": [
    "keeperlist = ['FID', 'FIPS', 'OBJECTID', 'SHAPE', 'SQMI', 'STATE_FIPS', 'STATE_NAME', 'Shape_Area', 'Shape_Leng', \n",
    "              'Shape__Area', 'Shape__Length']\n",
    "\n",
    "# FIPS = sdf.FIPS\n",
    "# print(FIPS.head())\n",
    "\n",
    "for i in list(sdf):\n",
    "    if not i in keeperlist:\n",
    "        del sdf[i]\n",
    "\n",
    "print(list(sdf))     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get and Format Drought Data\n",
    "https://open.cdc.gov/apis.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8.\n",
    "**create a string that can take inputs of minimum year, minimum month and maximum month.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year > '1998' AND month IN ('6','7','8')\n"
     ]
    }
   ],
   "source": [
    "# from our inputs ... this will control which months the drought data is gathered from (1-12 would get all months)\n",
    "# I have set it to 6-8 because we have found that june through august is most important for forest conditions\n",
    "# later on the palmer drought severity index values are averaged over these months\n",
    "\n",
    "monthlist = list(range(minmonth,maxmonth+1))\n",
    "final = str()\n",
    "length = len(monthlist) - 1\n",
    "\n",
    "for idx,i in enumerate(monthlist):\n",
    "    if idx < length:\n",
    "        string1 = \"'{}',\".format(i)\n",
    "        final = final + string1\n",
    "    else:\n",
    "        string1 = \"'{}'\".format(i)\n",
    "        final = final + string1\n",
    "    \n",
    "monthstring = \" AND month IN ({})\".format(final)\n",
    "\n",
    "# minimum value for this clause is 1894\n",
    "clause = \"year > '{}'\".format(minyear) + monthstring\n",
    "\n",
    "print(clause)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9. \n",
    "**Using sodapy library (recommended by CDC) get the drought data from CDC API.** set limit to something large so we get all records (if excluded will only get 1000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    }
   ],
   "source": [
    "# this gets the pdsi data from cdc website using the query speciried in the get() function\n",
    "\n",
    "client = sodapy.Socrata(\"data.cdc.gov\", None)\n",
    "results = client.get(\"en5r-5ds4\", where=clause, limit = 10000000)\n",
    "pdsi = pd.DataFrame.from_records(results)\n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year month statefips countyfips   pdsi\n",
      "0  1999     6         1       1001   1.24\n",
      "1  1999     6         1       1003  -1.51\n",
      "2  1999     6         1       1005   1.41\n",
      "3  1999     6         1       1007   1.24\n",
      "4  1999     6         1       1009   1.81\n",
      "167886\n"
     ]
    }
   ],
   "source": [
    "print(pdsi.head(5))\n",
    "print(len(pdsi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10.\n",
    "**change datatypes of all columns.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure all countyfips are stored as integers\n",
    "# countyfips is used to join to the layer\n",
    "# these are originally stored as text\n",
    "\n",
    "intlist = [\"countyfips\",\"year\",\"month\",\"statefips\"]\n",
    "\n",
    "for i in list(pdsi):\n",
    "    if i in intlist:\n",
    "        pdsi[str(i)] = pd.to_numeric(pdsi[str(i)],downcast='integer')\n",
    "    else:\n",
    "        pdsi[str(i)] = pd.to_numeric(pdsi[str(i)],downcast='float')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11.\n",
    "**iterate through yearlist and store dataframes in dictionary.** merge all dataframes to one dataframe called all_drought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get the maximum value from pdsi[\"year\"] column\n",
    "maxyear = max(pdsi[\"year\"])\n",
    "\n",
    "# min year plus one because we used > min year not => minyear\n",
    "# we will iterate through this list and use values as keys/column names\n",
    "\n",
    "yearlist = list(range(minyear+1,maxyear+1))\n",
    "\n",
    "# create dictionary to easily store dataframes as we iterate\n",
    "D = {}\n",
    "\n",
    "# enumerate the list so we can know when we are on the first iteration (see below)\n",
    "\n",
    "for idx,i in enumerate(yearlist):\n",
    "    # get values where year == i\n",
    "    D[i] = pdsi[pdsi.year == i]\n",
    "    # monthlist defined in step 8\n",
    "    D[i] = D[i][D[i].month.isin(monthlist)]\n",
    "    # groupby county and find the average pdsi across the months in our list\n",
    "    D[i] = D[i].groupby(['countyfips'])[['pdsi']].mean().reset_index()\n",
    "    # get a string of the value in yearlist\n",
    "    yearsuf = str(i)\n",
    "    # create a column name\n",
    "    pdsiname = \"pdsi{}\".format(yearsuf)\n",
    "    # reassign the column name to the PDSI column\n",
    "    D[i] = D[i].rename(columns={'pdsi': pdsiname})\n",
    "    # if it is the first iteration than store the dataframe as all_drought\n",
    "    if idx == 0:\n",
    "        all_drought = D[i]\n",
    "    # otherwise merge the dataframes on the county number\n",
    "    else:\n",
    "        all_drought = all_drought.merge(D[i], how='inner', on='countyfips')\n",
    "    # print(len(all_drought))\n",
    "\n",
    "del D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12.\n",
    "**Make sure that FIPS in the spatial dataframe is stored as an integer. Then merge the drought data to the county data using the countyfips and FIPS keys.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf['FIPS'] = pd.to_numeric(sdf['FIPS'],downcast='integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdsicounty = sdf.merge(all_drought, how='inner', left_on='FIPS', right_on='countyfips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FID  OBJECTID    STATE_NAME STATE_FIPS   FIPS    SQMI  Shape_Leng  \\\n",
      "0   19      1215  South Dakota         46  46029  717.30    1.933182   \n",
      "1   22      1218  South Dakota         46  46039  636.68    1.730427   \n",
      "2   27      1223  South Dakota         46  46057  538.03    1.741057   \n",
      "3   56      1252       Alabama         01   1011  625.05    2.006250   \n",
      "4   57      1253       Alabama         01   1013  777.88    1.769462   \n",
      "\n",
      "   Shape_Area   Shape__Area  Shape__Length  ...  pdsi2007  pdsi2008  pdsi2009  \\\n",
      "0    0.216860  3.799034e+09  247886.441856  ...  3.336667  2.440000  4.470000   \n",
      "1    0.186499  3.254596e+09  231916.025980  ...  3.243333  2.813334  4.300000   \n",
      "2    0.158622  2.764034e+09  217296.620249  ...  3.243333  2.813334  4.300000   \n",
      "3    0.155727  2.278179e+09  241042.982881  ... -4.353333 -1.440000  1.216667   \n",
      "4    0.192731  2.808881e+09  213677.638219  ... -3.636667 -1.366667  1.493333   \n",
      "\n",
      "   pdsi2010  pdsi2011  pdsi2012  pdsi2013  pdsi2014  pdsi2015  pdsi2016  \n",
      "0  6.980000  6.353333 -2.173333  2.050000  3.493333      1.57  0.623333  \n",
      "1  7.663333  5.400000 -2.050000  2.210000  3.056667      1.47  1.613333  \n",
      "2  7.663333  5.400000 -2.050000  2.210000  3.056667      1.47  1.613333  \n",
      "3 -1.200000 -3.420000 -1.523333  2.396667  0.300000     -1.48 -1.236667  \n",
      "4 -1.973333 -4.216667  0.543333  2.393333 -0.640000     -1.72 -0.920000  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pdsicounty.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FID', 'OBJECTID', 'STATE_NAME', 'STATE_FIPS', 'FIPS', 'SQMI', 'Shape_Leng', 'Shape_Area', 'Shape__Area', 'Shape__Length', 'SHAPE', 'countyfips', 'pdsi1999', 'pdsi2000', 'pdsi2001', 'pdsi2002', 'pdsi2003', 'pdsi2004', 'pdsi2005', 'pdsi2006', 'pdsi2007', 'pdsi2008', 'pdsi2009', 'pdsi2010', 'pdsi2011', 'pdsi2012', 'pdsi2013', 'pdsi2014', 'pdsi2015', 'pdsi2016']\n"
     ]
    }
   ],
   "source": [
    "print(list(pdsicounty))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13.\n",
    "**write our merged spatial dataframe to a feature class.**  store it in the geodatabase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\hjs5td\\\\Desktop\\\\SudekumFinalProject\\\\AdvGIS_proj.gdb\\\\pdsi'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdsipath = os.path.join(workspace,\"pdsi\")\n",
    "\n",
    "pdsicounty.spatial.to_featureclass(location = pdsipath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get and Download Population Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 14.\n",
    "**access the census API for county level population estimates using for years 2000 to 2010**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## see https://api.census.gov/data/2000/pep/int_population/examples.html ##\n",
    "\n",
    "# this gets county level population estimates from 2000 to 2010\n",
    "\n",
    "URL = \"https://api.census.gov/data/2000/pep/int_population?get=COUNTY,DATE_DESC,POP,GEONAME&for=county:*&in=state:*&key={}\".format(key)\n",
    "\n",
    "data = requests.get(URL)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 15.\n",
    "**convert json to nested list using the json() function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "datajson = data.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 16.\n",
    "**use pandas to write a dataframe from the datajson list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = pd.DataFrame.from_records(datajson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0                                   1      2                        3  \\\n",
      "0  COUNTY                           DATE_DESC    POP                  GEONAME   \n",
      "1     003  4/1/2000 population estimates base  73943  Aroostook County, Maine   \n",
      "2     003        7/1/2000 population estimate  73872  Aroostook County, Maine   \n",
      "3     003        7/1/2001 population estimate  72962  Aroostook County, Maine   \n",
      "4     003        7/1/2002 population estimate  72942  Aroostook County, Maine   \n",
      "\n",
      "       4       5  \n",
      "0  state  county  \n",
      "1     23     003  \n",
      "2     23     003  \n",
      "3     23     003  \n",
      "4     23     003  \n",
      "38653\n"
     ]
    }
   ],
   "source": [
    "print(cp.head())\n",
    "print(len(cp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 17.\n",
    "**make the first row the coulumn names and drop that row**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp.columns = cp.iloc[0]\n",
    "cp = cp.reindex(cp.index.drop(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COUNTY', 'DATE_DESC', 'POP', 'GEONAME', 'state', 'county']\n",
      "38652\n"
     ]
    }
   ],
   "source": [
    "print(list(cp))\n",
    "print(len(cp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 COUNTY                           DATE_DESC    POP                  GEONAME  \\\n",
      "1    003  4/1/2000 population estimates base  73943  Aroostook County, Maine   \n",
      "2    003        7/1/2000 population estimate  73872  Aroostook County, Maine   \n",
      "3    003        7/1/2001 population estimate  72962  Aroostook County, Maine   \n",
      "4    003        7/1/2002 population estimate  72942  Aroostook County, Maine   \n",
      "5    003        7/1/2003 population estimate  72944  Aroostook County, Maine   \n",
      "\n",
      "0 state county  \n",
      "1    23    003  \n",
      "2    23    003  \n",
      "3    23    003  \n",
      "4    23    003  \n",
      "5    23    003  \n"
     ]
    }
   ],
   "source": [
    "print(cp.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 18.\n",
    "**do the same thing for county level data from 2010 to 2018**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if we do not include \"DATE_CODE\" than we only get the 2018 estimate\n",
    "URL = \"https://api.census.gov/data/2018/pep/population?get=COUNTY,DATE_CODE,DATE_DESC,POP,GEONAME&for=county:*&in=state:*&key={}\".format(key)\n",
    "\n",
    "data = requests.get(URL)\n",
    "\n",
    "datajson = data.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncp = pd.DataFrame.from_records(datajson)\n",
    "\n",
    "ncp.columns = ncp.iloc[0]\n",
    "ncp = ncp.reindex(ncp.index.drop(0))\n",
    "\n",
    "# delete DATE_CODE\n",
    "del ncp[\"DATE_CODE\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 19. \n",
    "**concatenate the two dataframes (stack them on top of one another); must have same columns; reset the index so that all values are unique and delete the old index column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we redefine cp here make sure that we rerun the first request sequence before we concatanate dataframes again\n",
    "\n",
    "cp = pd.concat([ncp,cp], axis=0, sort = False, join='outer',ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = cp.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cp[\"index\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 20. \n",
    "**iterate through the indexes of the cp dataframe to format the FIPS and year variables.** I tried usiung datetime package but it was simpler to just format it on my own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringlist = [\"population estimate\", \"population estimates base\",\"Census 2010 population\",\"Census population\"]\n",
    "\n",
    "# create an empty column year\n",
    "cp[\"year\"] = \"\"\n",
    "#create an empty column FIPS\n",
    "cp[\"FIPS\"] = \"\"\n",
    "#create an empty list to store year values\n",
    "yearlist = list()\n",
    "\n",
    "# iterate through the indexs\n",
    "# iterating through a pandas dataframe\n",
    "for i in cp.index:\n",
    "    datestr = cp.at[i,\"DATE_DESC\"]\n",
    "    county = str(cp.at[i,\"county\"])\n",
    "    state = str(cp.at[i,\"state\"])\n",
    "    FIPS = int(state + county)\n",
    "    cp.at[i,\"FIPS\"] = FIPS\n",
    "    # if any(x in datestr for x in stringlist):\n",
    "    for y in stringlist:\n",
    "        # check to see if datestr created above ends with any value in the list\n",
    "        if datestr.endswith(y):\n",
    "            # get the length of the text that the datestr endswith\n",
    "            length = len(y)\n",
    "            # create a negative integer value from that length\n",
    "            position = -length\n",
    "            # new string excluding that text\n",
    "            new_datestr = datestr[:position]\n",
    "            # new string excluding month and day\n",
    "            # includes the space and the year I beleive\n",
    "            new_year = new_datestr[-5:]\n",
    "            # convert to integer\n",
    "            year = int(new_year)\n",
    "            # assign value\n",
    "            cp.at[i,\"year\"] = year\n",
    "            # to check the min and max later on\n",
    "            yearlist.append(year)\n",
    "\n",
    "# we need to drop duplicates because each county includes a baseline 2000 census estimate and an additional 2000 estimate\n",
    "# I sort values so that we are always dropping the baseline estimate\n",
    "            \n",
    "cp = cp.sort_values(['state','county','year'], axis=0, ascending=True,kind='quicksort', na_position='first')\n",
    "\n",
    "cp = cp.drop_duplicates(subset=['state','county','year'], keep='last', inplace=False)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 21.\n",
    "**create a new list of the minimum year and the maximum years found in the dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COUNTY', 'DATE_DESC', 'POP', 'GEONAME', 'state', 'county', 'year', 'FIPS']\n"
     ]
    }
   ],
   "source": [
    "yeararray = np.array(yearlist)\n",
    "\n",
    "x = min(yeararray)\n",
    "y = max(yeararray)\n",
    "\n",
    "yearlist = list(range(x,y+1))\n",
    "\n",
    "del yeararray\n",
    "print(list(cp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 22.\n",
    "**select rows by year; rename column; mrege dataframes (same as drought method)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2001\n",
      "['pop2001', 'FIPS']\n",
      "2002\n",
      "['pop2002', 'FIPS']\n",
      "2003\n",
      "['pop2003', 'FIPS']\n",
      "2004\n",
      "['pop2004', 'FIPS']\n",
      "2005\n",
      "['pop2005', 'FIPS']\n",
      "2006\n",
      "['pop2006', 'FIPS']\n",
      "2007\n",
      "['pop2007', 'FIPS']\n",
      "2008\n",
      "['pop2008', 'FIPS']\n",
      "2009\n",
      "['pop2009', 'FIPS']\n",
      "2010\n",
      "['pop2010', 'FIPS']\n",
      "2011\n",
      "['pop2011', 'FIPS']\n",
      "2012\n",
      "['pop2012', 'FIPS']\n",
      "2013\n",
      "['pop2013', 'FIPS']\n",
      "2014\n",
      "['pop2014', 'FIPS']\n",
      "2015\n",
      "['pop2015', 'FIPS']\n",
      "2016\n",
      "['pop2016', 'FIPS']\n",
      "2017\n",
      "['pop2017', 'FIPS']\n",
      "2018\n",
      "['pop2018', 'FIPS']\n"
     ]
    }
   ],
   "source": [
    "D = {}\n",
    "\n",
    "for idx,i in enumerate(yearlist):\n",
    "    print(i)\n",
    "    D[i] = cp[cp.year == i]\n",
    "    # groupby county and find the average pdsi\n",
    "    yearsuf = str(i)\n",
    "    name = \"pop{}\".format(yearsuf)\n",
    "    D[i] = D[i].rename(columns={'POP' : name})\n",
    "    if idx == 0:\n",
    "        all_pop = D[i]\n",
    "    else:\n",
    "        # get a subselection of columns\n",
    "        D[i] = D[i][[name, 'FIPS']]\n",
    "        print(list(D[i]))\n",
    "        all_pop = all_pop.merge(D[i], how='inner', on='FIPS')\n",
    "    #print(len(all_pop))\n",
    "    #print(idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 23.\n",
    "**merge pop data to spatial dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "popcounty = sdf.merge(all_pop, how='inner', on='FIPS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 24.\n",
    "**write population data to geodatabse**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\hjs5td\\\\Desktop\\\\SudekumFinalProject\\\\AdvGIS_proj.gdb\\\\pop'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poppath = os.path.join(workspace,\"pop\")\n",
    "\n",
    "\n",
    "popcounty.spatial.to_featureclass(location = poppath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 25.\n",
    "**Spatial Joins of Point**\n",
    "\n",
    "https://developers.arcgis.com/python/guide/spatially-enabled-dataframe-advanced-topics/#Spatial-Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'temppop'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.MakeFeatureLayer_management(plots_proj, 'tempplots')\n",
    "arcpy.MakeFeatureLayer_management(pdsipath, 'temppdsi')\n",
    "arcpy.MakeFeatureLayer_management(poppath, 'temppop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = arcpy.ListFields('tempplots')\n",
    "origlist = list()\n",
    "\n",
    "\n",
    "for i in orig:\n",
    "    x = i.name\n",
    "    origlist.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'C:\\\\Users\\\\hjs5td\\\\Desktop\\\\SudekumFinalProject\\\\AdvGIS_proj.gdb\\\\temporaryjoin'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = \"temporaryjoin\"\n",
    "\n",
    "arcpy.SpatialJoin_analysis('tempplots','temppop',temp, join_operation = 'JOIN_ONE_TO_ONE', join_type = 'KEEP_ALL', match_option = 'CLOSEST')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'C:\\\\Users\\\\hjs5td\\\\Desktop\\\\SudekumFinalProject\\\\AdvGIS_proj.gdb\\\\temporatyjoin1'>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp1 = \"temporatyjoin1\"\n",
    "\n",
    "arcpy.SpatialJoin_analysis(temp,'temppdsi',temp1, join_operation = 'JOIN_ONE_TO_ONE', join_type = 'KEEP_ALL', match_option = 'CLOSEST')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 26.\n",
    "**convert to spatial dataframe and format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pltdf = pd.DataFrame.spatial.from_featureclass(temp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "deletelist = ['OBJECTID',\n",
    " 'Join_Count',\n",
    " 'TARGET_FID',\n",
    " 'Join_Count_1',\n",
    " 'TARGET_FID_1',\n",
    " 'Field1',\n",
    " 'FID_1',\n",
    " 'FIPS_1',\n",
    " 'SQMI_1',\n",
    " 'STATE_FIPS_1',\n",
    " 'STATE_NAME_1',\n",
    " 'Shape_Leng_1',\n",
    " 'Shape__Area_1',\n",
    " 'Shape__Length_1',\n",
    " 'countyfips',\n",
    " 'STATE_FIPS',\n",
    " 'STATE_NAME',\n",
    " 'Shape_Leng',\n",
    " 'Shape__Area',\n",
    " 'Shape__Length',\n",
    " 'COUNTY',\n",
    " 'DATE_DESC','FID']\n",
    "\n",
    "for i in deletelist:\n",
    "    if hasattr(pltdf, i):\n",
    "        del pltdf[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearlist = list(range(2000,2018))\n",
    "columnlist = list(pltdf)\n",
    "\n",
    "pltdf['final_pdsi'] = \"\"\n",
    "pltdf['final_pop'] = \"\"\n",
    "\n",
    "for i in pltdf.index:\n",
    "    popstr = str(int(pltdf.at[i,plot_year]))\n",
    "    # we do this because we are interested in drought of the previous year rather than drought of the current year\n",
    "    pdsistr = str(int(pltdf.at[i,plot_year]) - 1)\n",
    "    for y in columnlist:\n",
    "        # search for columns with the name\n",
    "        if popstr in y:\n",
    "            if y.startswith('pop'):\n",
    "                pltdf.at[i,\"final_pop\"] = pltdf.at[i,y]\n",
    "        elif pdsistr in y:\n",
    "            if y.startswith('pdsi'):\n",
    "                pltdf.at[i,\"final_pdsi\"] = pltdf.at[i,y]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "newlist = ['FIPS','SQMI','final_pdsi','final_pop']\n",
    "for i in newlist:\n",
    "    origlist.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in list(pltdf):\n",
    "    if not y in origlist:\n",
    "        del pltdf[y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 27.\n",
    "**create a relative population from square miles and the correct population**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pltdf['final_pop'] = pd.to_numeric(pltdf['final_pop'],downcast='float')\n",
    "pltdf['SQMI'] = pd.to_numeric(pltdf['SQMI'],downcast='float')\n",
    "\n",
    "pltdf.loc[:,'poparea'] = pltdf.final_pop / pltdf.SQMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 28.\n",
    "**write our results to a csv and a featureclass**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotpath = os.path.join(workspace,\"update_plots\")\n",
    "out = os.path.join(space,'out_data')\n",
    "csvpath = os.path.join(out,\"SudekumPlotSampleUpdate.csv\")\n",
    "\n",
    "pdsicounty.spatial.to_featureclass(location = plotpath)\n",
    "pltdf.to_csv(csvpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
